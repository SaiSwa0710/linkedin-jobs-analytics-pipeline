{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2HxhrAmA8_Q",
        "outputId": "dc6b35e6-d6c3-462e-a61c-52c5e8eae07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqIpAiGOA-O_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgJPb9WIAc0Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6I2Ei7LA5Vt"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"jobs_transfer_temp.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yXoXDJuBRR_"
      },
      "outputs": [],
      "source": [
        "df_skills = df[[\"job_link\", \"skills_array\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KTa1nfOwBV94",
        "outputId": "28197d75-5bcf-4ed9-8df8-c04aecf321f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_skills"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f6c71f15-a798-4fca-a209-2310882141b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_link</th>\n",
              "      <th>skills_array</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://ca.linkedin.com/jobs/view/team-lead-se...</td>\n",
              "      <td>[Troubleshooting, Ticketing Systems, IT System...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/i-e-designe...</td>\n",
              "      <td>[Instrument &amp; Control System Design, 2D AUTOCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/client-rela...</td>\n",
              "      <td>[Client Relations Management (CRM), Communicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/private-dut...</td>\n",
              "      <td>[LPN license, CPR certification, Inhome nursin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/procurement...</td>\n",
              "      <td>[Procurement, Leadership, Stakeholder alignmen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6c71f15-a798-4fca-a209-2310882141b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6c71f15-a798-4fca-a209-2310882141b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6c71f15-a798-4fca-a209-2310882141b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-88b6b2db-9379-4015-b7fc-822ea1fd1344\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88b6b2db-9379-4015-b7fc-822ea1fd1344')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-88b6b2db-9379-4015-b7fc-822ea1fd1344 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            job_link  \\\n",
              "0  https://ca.linkedin.com/jobs/view/team-lead-se...   \n",
              "1  https://www.linkedin.com/jobs/view/i-e-designe...   \n",
              "2  https://www.linkedin.com/jobs/view/client-rela...   \n",
              "3  https://www.linkedin.com/jobs/view/private-dut...   \n",
              "4  https://www.linkedin.com/jobs/view/procurement...   \n",
              "\n",
              "                                        skills_array  \n",
              "0  [Troubleshooting, Ticketing Systems, IT System...  \n",
              "1  [Instrument & Control System Design, 2D AUTOCA...  \n",
              "2  [Client Relations Management (CRM), Communicat...  \n",
              "3  [LPN license, CPR certification, Inhome nursin...  \n",
              "4  [Procurement, Leadership, Stakeholder alignmen...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_skills.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from itertools import chain\n",
        "import numpy as np\n",
        "import hdbscan\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from itertools import chain\n",
        "from sklearn.decomposition import PCA\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "import cupy as cp\n",
        "from cuml.cluster import KMeans\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from scipy.spatial.distance import cdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqWSwTJgBnyt",
        "outputId": "28f140d4-4c0f-422a-bc1a-371c4765907a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of unique skills: 3298136\n"
          ]
        }
      ],
      "source": [
        "skills_lists = [s for s in df_skills[\"skills_array\"] if s is not None]\n",
        "\n",
        "all_skills = list(chain.from_iterable(skills_lists))\n",
        "\n",
        "unique_skills = set(all_skills)\n",
        "\n",
        "print(\"Total number of unique skills:\", len(unique_skills))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxIWd-o1DGdi",
        "outputId": "bbc7c073-6a87-4b97-d0df-3469c5015860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalizing skills...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Normalizing skills: 100%|██████████| 3298136/3298136 [00:02<00:00, 1209785.78it/s]\n"
          ]
        }
      ],
      "source": [
        "def normalize_skill(skill):\n",
        "    return str(skill).lower().strip()\n",
        "\n",
        "print(\"Normalizing skills...\")\n",
        "normalized_skills = [normalize_skill(s) for s in tqdm(unique_skills, desc=\"Normalizing skills\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R13QlkXXEpim",
        "outputId": "f3b35655-98ba-4d5c-d5f3-a80efe0fb81c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3WEFlDCEwvH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
        "\n",
        "reduced_dim = 32\n",
        "batch_size = 2048\n",
        "num_skills = len(normalized_skills)\n",
        "sample_size = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OkkkahcG97T",
        "outputId": "8f2f434f-b20e-4034-b9f1-bfca3283c33a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sampling embeddings for PCA: 100%|██████████| 25/25 [00:11<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA fit complete. Explained variance ratio: 0.41\n"
          ]
        }
      ],
      "source": [
        "sample_embeddings = []\n",
        "for i in tqdm(range(0, sample_size, batch_size), desc=\"Sampling embeddings for PCA\"):\n",
        "    batch = normalized_skills[i:i+batch_size]\n",
        "    with torch.no_grad():\n",
        "        emb = model.encode(batch, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
        "    sample_embeddings.append(emb.cpu())\n",
        "sample_embeddings = torch.cat(sample_embeddings).numpy()\n",
        "\n",
        "pca = PCA(n_components=reduced_dim)\n",
        "pca.fit(sample_embeddings)\n",
        "print(f\"PCA fit complete. Explained variance ratio: {np.sum(pca.explained_variance_ratio_):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg5VPQXWHCd8",
        "outputId": "57c88f09-6912-42bb-dadb-e20a8ded93db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding + PCA batches: 100%|██████████| 1611/1611 [13:22<00:00,  2.01it/s]\n"
          ]
        }
      ],
      "source": [
        "reduced_embeddings = []\n",
        "for i in tqdm(range(0, len(normalized_skills), batch_size), desc=\"Embedding + PCA batches\"):\n",
        "    batch = normalized_skills[i:i+batch_size]\n",
        "    with torch.no_grad():\n",
        "        emb = model.encode(batch, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
        "    emb = emb.cpu().numpy()\n",
        "    emb_reduced = pca.transform(emb)\n",
        "    reduced_embeddings.append(emb_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaHNBIqtMiWE",
        "outputId": "92950020-0504-4906-e1ce-d35542452b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 3298136 embeddings + normalized skills to Parquet in batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Writing embeddings: 100%|██████████| 66/66 [00:22<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done! Embeddings + normalized skills saved to Parquet at skills_embeddings_32d.parquet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "flat_embeddings = np.vstack(reduced_embeddings)\n",
        "assert flat_embeddings.shape[0] == len(normalized_skills), \"Embeddings and skills length mismatch!\"\n",
        "\n",
        "output_path = \"skills_embeddings_32d.parquet\"\n",
        "batch_size = 50000\n",
        "writer = None\n",
        "\n",
        "print(f\"Saving {len(normalized_skills)} embeddings + normalized skills to Parquet in batches...\")\n",
        "\n",
        "for start_idx in tqdm(range(0, len(normalized_skills), batch_size), desc=\"Writing embeddings\"):\n",
        "    end_idx = min(start_idx + batch_size, len(normalized_skills))\n",
        "\n",
        "    batch_skills = normalized_skills[start_idx:end_idx]\n",
        "    batch_embeddings = flat_embeddings[start_idx:end_idx].tolist()\n",
        "\n",
        "    batch_df = pd.DataFrame({\n",
        "        \"skill_normalized\": batch_skills,\n",
        "        \"embedding\": batch_embeddings\n",
        "    })\n",
        "\n",
        "    table = pa.Table.from_pandas(batch_df)\n",
        "\n",
        "    if writer is None:\n",
        "        writer = pq.ParquetWriter(output_path, table.schema)\n",
        "    writer.write_table(table)\n",
        "\n",
        "    del batch_df, table, batch_embeddings\n",
        "\n",
        "if writer:\n",
        "    writer.close()\n",
        "\n",
        "print(f\"Done! Embeddings + normalized skills saved to Parquet at {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T3vdVK6OLQC",
        "outputId": "852af9a1-b85a-4d41-b5c6-cd0af2f38977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               skill_normalized  \\\n",
            "0         web and mobile trends   \n",
            "1                           mqb   \n",
            "2        highquality recruiting   \n",
            "3  integrated hardware/software   \n",
            "4                  pos strategy   \n",
            "\n",
            "                                           embedding  \n",
            "0  [0.15919700264930725, 0.07573260366916656, 0.1...  \n",
            "1  [0.031084492802619934, -0.11332739889621735, 0...  \n",
            "2  [-0.20707492530345917, 0.26148080825805664, 0....  \n",
            "3  [0.23487156629562378, 0.06972840428352356, -0....  \n",
            "4  [0.19313479959964752, 0.016096383333206177, 0....  \n"
          ]
        }
      ],
      "source": [
        "parquet_path = \"skills_embeddings_32d.parquet\"\n",
        "\n",
        "df = pq.read_table(parquet_path).to_pandas()\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFLBtYDmLpWc",
        "outputId": "37a9b8af-5867-40c2-d2ba-8a91beb93ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings batch-wise from skills_embeddings_32d.parquet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reading row groups: 100%|██████████| 66/66 [00:14<00:00,  4.43rg/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All batches loaded.\n",
            "Embeddings shape: (3298136, 32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "parquet_path = \"skills_embeddings_32d.parquet\"\n",
        "num_clusters = 1000\n",
        "batch_size = 50000\n",
        "\n",
        "parquet_file = pq.ParquetFile(parquet_path)\n",
        "num_row_groups = parquet_file.num_row_groups\n",
        "all_skills = []\n",
        "all_emb_batches = []\n",
        "\n",
        "print(f\"Loading embeddings batch-wise from {parquet_path}...\")\n",
        "for rg_idx in tqdm(range(num_row_groups), desc=\"Reading row groups\", unit=\"rg\"):\n",
        "    batch_df = parquet_file.read_row_group(rg_idx).to_pandas()\n",
        "    batch_emb = np.vstack(batch_df[\"embedding\"].values)\n",
        "    batch_skills = batch_df[\"skill_normalized\"].tolist()\n",
        "\n",
        "    all_emb_batches.append(batch_emb)\n",
        "    all_skills.extend(batch_skills)\n",
        "\n",
        "print(\"All batches loaded.\")\n",
        "\n",
        "emb_gpu = cp.array(np.vstack(all_emb_batches), dtype=cp.float32)\n",
        "print(f\"Embeddings shape: {emb_gpu.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb6uOffVNmmq",
        "outputId": "7dfa80e1-878a-4c7c-e842-2892b919e518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clustering 3298136 skills into 2000 clusters on GPU...\n",
            "Clustering complete.\n",
            "Canonical clusters saved to: skills_canonical_clusters.parquet\n"
          ]
        }
      ],
      "source": [
        "num_clusters = 2000\n",
        "print(f\"Clustering {emb_gpu.shape[0]} skills into {num_clusters} clusters on GPU...\")\n",
        "kmeans = KMeans(n_clusters=num_clusters, max_iter=300)\n",
        "\n",
        "labels = kmeans.fit_predict(emb_gpu)\n",
        "print(\"Clustering complete.\")\n",
        "\n",
        "df_clusters = pd.DataFrame({\n",
        "    \"skill_normalized\": all_skills,\n",
        "    \"cluster\": labels.get()\n",
        "})\n",
        "\n",
        "output_path = \"skills_canonical_clusters.parquet\"\n",
        "df_clusters.to_parquet(output_path, index=False)\n",
        "print(f\"Canonical clusters saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxSCLoC4QQOJ",
        "outputId": "56cbc595-7668-4bf4-bba8-5076c9008e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in the parquet: ['skill_normalized', 'cluster']\n",
            "\n",
            "First 5 rows:\n",
            "               skill_normalized  cluster\n",
            "0         web and mobile trends     1455\n",
            "1                           mqb      331\n",
            "2        highquality recruiting     1250\n",
            "3  integrated hardware/software      831\n",
            "4                  pos strategy      819\n",
            "\n",
            "Number of unique clusters: 2000\n",
            "\n",
            "Cluster sizes:\n",
            "cluster\n",
            "926     5997\n",
            "1       5756\n",
            "1559    5682\n",
            "902     5642\n",
            "1474    5551\n",
            "415     5353\n",
            "1148    5320\n",
            "1033    5298\n",
            "313     5194\n",
            "1330    5041\n",
            "197     4933\n",
            "659     4862\n",
            "1615    4759\n",
            "194     4726\n",
            "1878    4713\n",
            "580     4671\n",
            "1048    4642\n",
            "331     4531\n",
            "1433    4385\n",
            "77      4361\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "parquet_path = \"skills_canonical_clusters.parquet\"\n",
        "df_clusters = pd.read_parquet(parquet_path)\n",
        "\n",
        "print(\"Columns in the parquet:\", df_clusters.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df_clusters.head())\n",
        "\n",
        "# top 20 largest clusters\n",
        "print(\"\\nNumber of unique clusters:\", df_clusters['cluster'].nunique())\n",
        "print(\"\\nCluster sizes:\")\n",
        "print(df_clusters['cluster'].value_counts().head(20))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4rhFAXCSVtr",
        "outputId": "760e4874-aba9-49c8-d579-84bd390d0c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample clusters and their skills:\n",
            "\n",
            "Cluster 1952 (2821 skills):\n",
            "['peo pgo cet pmp certifications', 'cpvc and pex certification', 'cphon certification', 'cprss certification', 'cpi or nappi certification', 'pmi pmp certification', 'cqi (cphq) certification', 'rmf certification', 'cpsm cscp cpp certifications', 'treasury professional certification', 'quality control management course certification', 'arizona: bls certification cma rma or ccma certification', 'scm certification', 'cpc cpch cca rhia rhit ccs ccsp certified', 'pmac / cpp certification', 'cca or cdt (csi)', 'cprbls certification (caha/aapnrp)', 'cpr/bls/acls/nrp certification', 'ccure9000 enterprise certification', 'rn efm certification']\n",
            "...\n",
            "Cluster 1338 (1412 skills):\n",
            "['selfmedication administration', 'pain management focus', 'chronic disease management', 'difficult airway management', 'cardiac rhythm management procedures', 'highpressure situations management', 'medical and behavioral concerns management', 'illness management and recovery', 'incidence management', 'rheumatoid arthritis management', 'concur/motus management', 'multisystem disease processes', 'patient symptom management', 'physical health maintenance', 'bowel and bladder management', 'patient pathway management', 'sleep care management', 'rush system for health', 'ageing management', 'administrative remedies']\n",
            "...\n",
            "Cluster 1293 (672 skills):\n",
            "['risk engineer or risk management experience', '5 years environmental health & safety experience', '4 years of air quality permitting and compliance experience (air quality professionals)', 'health and safety qualification and experience', '10+ years of safety role experience', 'risk and compliance experience', 'experience working in dangerous goods compliance', 'minimum of five (5) years leadership experience in fire and rescue / emergency response in a manufacturing setting', '10+ years of experience in safety health environmental or related field', 'experience in environmental or safety management', 'fire protection consulting', 'health safety and environmental experience/qualification', 'experience as health and safety manager', 'management experience in risk management/safety area', '5+ years experience in progressive safety role', 'safetyrelated experience', '7 years experience in fire protection engineering', 'experience in trust and safety', 'experience as an adult protective services investigator specialist', '5 years of experience in safety or related field']\n",
            "...\n",
            "Cluster 432 (1478 skills):\n",
            "['12 years experience as cook/chef', 'two to five years of pantry experience', 'minimum of 3 years of experience in food manufacturing or cpg', 'two years of food service experience', 'one (1) year minimum of scratch cooking experience', 'minimum 3 years professional culinary experience', 'culinary experience', '5+ years of experience in culinary/kitchen management', '3 years as exec chef exec sous cdc or similar role', '6 months of experience in food and beverage service', 'minimum two years of catering experience', '2 years’ experience in food service work', 'at least 1 year of food and beverage experience', '3+ years cooking experience or culinary certification', '2 years of experience in high volume and fine dining restaurants', 'six months of food handling experience', '2 years highend kitchen experience', 'two years of hotel or restaurant line cooking', 'two years of experience in dining/nutrition', 'minimum one (1) year of restaurant experience']\n",
            "...\n",
            "Cluster 150 (844 skills):\n",
            "['it project experience in insurance industry', 'three years of insurance underwriting or brokering experience', '3+ years of commercial insurance experience', 'lead level: minimum of one year experience with long term care insurance care management', 'insurance company income tax experience', 'prior claims experience (preferred)', '2+ years general liability experience', 'experience in health benefits managed care and/or underwriting', 'insurance underwriting experience', 'direct life insurance selling experience', '10 years of personal lines property & casualty insurance experience', 'previous insurance brokerage experience', '5+ years personal insurance agency experience', 'one year registration or insurance experience', 'prior experience in insurance industry', 'insurance regulatory experience', '3+ years risk analysis experience', 'experience working in an insurance company', '12 years of life insurance experience', 'managed longterm care insurance experience']\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "sample_clusters = df_clusters['cluster'].drop_duplicates().sample(5, random_state=100).tolist()\n",
        "\n",
        "print(\"Sample clusters and their skills:\\n\")\n",
        "for c in sample_clusters:\n",
        "    skills_in_cluster = df_clusters[df_clusters['cluster'] == c]['skill_normalized'].tolist()\n",
        "    print(f\"Cluster {c} ({len(skills_in_cluster)} skills):\")\n",
        "    print(skills_in_cluster[:20])\n",
        "    print(\"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQXy9P6SSnCX",
        "outputId": "7bd55aa8-c4e2-4958-954b-a3b8b2ce7d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading skills embeddings parquet...\n",
            "Sample of embeddings:\n",
            "               skill_normalized  \\\n",
            "0         web and mobile trends   \n",
            "1                           mqb   \n",
            "2        highquality recruiting   \n",
            "3  integrated hardware/software   \n",
            "4                  pos strategy   \n",
            "\n",
            "                                           embedding  \n",
            "0  [0.15919700264930725, 0.07573260366916656, 0.1...  \n",
            "1  [0.031084492802619934, -0.11332739889621735, 0...  \n",
            "2  [-0.20707492530345917, 0.26148080825805664, 0....  \n",
            "3  [0.23487156629562378, 0.06972840428352356, -0....  \n",
            "4  [0.19313479959964752, 0.016096383333206177, 0....  \n",
            "Clustering 3298136 skills into 2000 clusters...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "file_path = \"skills_embeddings_32d.parquet\"\n",
        "print(\"Reading skills embeddings parquet...\")\n",
        "parquet_file = pq.ParquetFile(file_path)\n",
        "df_embeddings = parquet_file.read().to_pandas()\n",
        "\n",
        "print(\"Sample of embeddings:\")\n",
        "print(df_embeddings.head())\n",
        "\n",
        "df_embeddings['embedding'] = df_embeddings['embedding'].apply(np.array)\n",
        "\n",
        "n_clusters = 2000\n",
        "print(f\"Clustering {len(df_embeddings)} skills into {n_clusters} clusters...\")\n",
        "emb_array = np.vstack(df_embeddings['embedding'].values)\n",
        "\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=8192, random_state=42)\n",
        "labels = kmeans.fit_predict(emb_array)\n",
        "\n",
        "df_embeddings['cluster'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FlhbUWBdo7k",
        "outputId": "3ca03b7e-1e8e-45b7-b044-3ca1d91dbb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing canonical skills from centroids...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing clusters: 100%|██████████| 2000/2000 [00:22<00:00, 88.68it/s] \n"
          ]
        }
      ],
      "source": [
        "unique_clusters = np.unique(labels)\n",
        "canonical_clusters = []\n",
        "\n",
        "print(\"Computing canonical skills from centroids...\")\n",
        "for c in tqdm(unique_clusters, desc=\"Processing clusters\"):\n",
        "    cluster_rows = df_embeddings[df_embeddings['cluster'] == c]\n",
        "    cluster_emb = np.vstack(cluster_rows['embedding'].values)\n",
        "\n",
        "    centroid = cluster_emb.mean(axis=0, keepdims=True)\n",
        "    distances = cdist(cluster_emb, centroid, metric='euclidean').flatten()\n",
        "    closest_idx = distances.argmin()\n",
        "    canonical_skill = cluster_rows.iloc[closest_idx]['skill_normalized']\n",
        "\n",
        "    canonical_clusters.append({\n",
        "        'canonical_skill': canonical_skill,\n",
        "        'clustered_skills': cluster_rows['skill_normalized'].tolist()\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjcRzj1HTutQ",
        "outputId": "b6e0d21c-e707-4ea5-cee6-c8b2ab939313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved clusters to parquet: skill_clusters_canonical.parquet\n",
            "Sample clusters:\n",
            "                                   canonical_skill  \\\n",
            "0                                property closings   \n",
            "1                       google calendar management   \n",
            "2  licensed registered nurse – mn board of nursing   \n",
            "3              technical review and interpretation   \n",
            "4                       verifying business changes   \n",
            "\n",
            "                                    clustered_skills  \n",
            "0  [highvalue property insurance, out of state pr...  \n",
            "1  [experience creating and managing editorial ca...  \n",
            "2  [nova scotia college of nursing (nscn) registr...  \n",
            "3  [engineering feedback, technical tests, techno...  \n",
            "4  [client matter aging reports, dsc vendor contr...  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "df_clusters = pd.DataFrame(canonical_clusters)\n",
        "output_path = \"skill_clusters_canonical.parquet\"\n",
        "\n",
        "table = pa.Table.from_pandas(df_clusters)\n",
        "pq.write_table(table, output_path)\n",
        "\n",
        "print(\"Saved clusters to parquet:\", output_path)\n",
        "print(\"Sample clusters:\")\n",
        "print(df_clusters.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6ziYCh7hXEW",
        "outputId": "d6e23bbb-7937-4b43-b532-c8ae2d072be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total mappings: 2770325\n"
          ]
        }
      ],
      "source": [
        "clusters = pq.read_table(\"skill_clusters_canonical.parquet\").to_pandas()\n",
        "\n",
        "skill_to_canonical = {}\n",
        "\n",
        "for _, row in clusters.iterrows():\n",
        "    canon = row[\"canonical_skill\"]\n",
        "    for s in row[\"clustered_skills\"]:\n",
        "        skill_to_canonical[s] = canon\n",
        "\n",
        "print(\"Total mappings:\", len(skill_to_canonical))\n",
        "\n",
        "\n",
        "input_file = \"jobs_transfer_temp.parquet\"\n",
        "output_file = \"jobs_transfer_retagged.parquet\"\n",
        "\n",
        "pf = pq.ParquetFile(input_file)\n",
        "writer = None\n",
        "\n",
        "def retag_list(skill_list):\n",
        "    if skill_list is None:\n",
        "        return []\n",
        "    if isinstance(skill_list, list):\n",
        "        return [skill_to_canonical.get(s, s) for s in skill_list]\n",
        "\n",
        "    return [skill_to_canonical.get(s, s) for s in list(skill_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgR2iEgLhd4U",
        "outputId": "d42e8c06-5c81-4917-ac7b-e9a79117a07d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retagging row groups: 100%|██████████| 4/4 [00:51<00:00, 12.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for rg in tqdm(range(pf.num_row_groups), desc=\"Retagging row groups\"):\n",
        "    batch = pf.read_row_group(rg).to_pandas()\n",
        "\n",
        "    batch[\"skills_canonical\"] = batch[\"skills_array\"].apply(retag_list)\n",
        "\n",
        "    table = pa.Table.from_pandas(batch)\n",
        "\n",
        "    if writer is None:\n",
        "        writer = pq.ParquetWriter(output_file, table.schema)\n",
        "\n",
        "    writer.write_table(table)\n",
        "\n",
        "writer.close()\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28VDesMuhhma",
        "outputId": "19b7d1fb-80d3-4dd0-dd19-57c8b51988d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data pickled successfully.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('map.pickle', 'wb') as f:\n",
        "    pickle.dump(skill_to_canonical, f)\n",
        "    print(\"Data pickled successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twU_enZDiWTn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
